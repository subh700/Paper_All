{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10472,
     "status": "ok",
     "timestamp": 1670665744936,
     "user": {
      "displayName": "Abhijeet Kumar",
      "userId": "18174877903277820406"
     },
     "user_tz": -330
    },
    "id": "cM5lBYh8b2xI",
    "outputId": "7e3b03e3-d967-494c-e83b-0e11f41e9920"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandasql in /home/subham/.local/lib/python3.10/site-packages (0.7.3)\n",
      "Requirement already satisfied: numpy in /home/subham/.local/lib/python3.10/site-packages (from pandasql) (1.22.4)\n",
      "Requirement already satisfied: pandas in /home/subham/.local/lib/python3.10/site-packages (from pandasql) (1.4.4)\n",
      "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.10/dist-packages (from pandasql) (1.4.44)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/subham/.local/lib/python3.10/site-packages (from pandas->pandasql) (2022.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/subham/.local/lib/python3.10/site-packages (from pandas->pandasql) (2.8.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy->pandasql) (2.0.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->pandasql) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "!pip install pandasql\n",
    "import pandasql as ps\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pandasql import sqldf\n",
    "pysqldf = lambda q: sqldf(q, globals()) \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.arima_model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21031,
     "status": "ok",
     "timestamp": 1670667010091,
     "user": {
      "displayName": "Abhijeet Kumar",
      "userId": "18174877903277820406"
     },
     "user_tz": -330
    },
    "id": "9PaP5o44b_v4",
    "outputId": "d6d6c880-a433-4da7-b7e9-fd393dc270cf"
   },
   "outputs": [],
   "source": [
    "df=pd.read_excel('ANKLESHWAR/H_Ankl_1_2_19-3_12_22-*41* (copy).xlsx',usecols={'CENTRAL POLLUTION CONTROL BOARD','Unnamed: 2'}) #read excel spacfioc colume and import\n",
    "df=df.reset_index(drop=True)\n",
    "N=1+15\n",
    "df.drop(index=df.index[:N], axis=0, inplace=True) # Drop row through N    (axis = o)=row\n",
    "d = df.rename(columns={'CENTRAL POLLUTION CONTROL BOARD':'Date','Unnamed: 2':'PM'}) # Colume ReName \n",
    "d['DD'] = d['Date'].str.split('-').str[0]   \n",
    "d['MM'] = d['Date'].str.split('-').str[1]\n",
    "d['YYYY'] = d['Date'].str.split('-').str[2]\n",
    "d['YYYY'] = d['YYYY'].map(lambda x: str(x)[:-6])\n",
    "d['Hour'] = d['Date'].str.split(' ').str[1]\n",
    "d['DATE']=d['YYYY']+'-'+d['MM']+'-'+d['DD']+' '+d['Hour']\n",
    "d['DATE']= pd.to_datetime(d['DATE'])\n",
    "d=d.drop(['Date','YYYY','DD','MM','Hour'],axis=1)\n",
    "d['row_num']=np.arange(len(d))\n",
    "q=\"\"\"SELECT row_num from d where PM is null limit 1\"\"\"    #sql query ########################Changes####################\n",
    "df1=ps.sqldf(q, locals())\n",
    "a=df1.values.flatten()\n",
    "b=(a[0])\n",
    "b\n",
    "d=d.iloc[:b,:] \n",
    "d['PM']=d['PM'].replace(0,'None')\n",
    "#q=\"\"\"SELECT row_num from d where PM is null limit 1\"\"\"    #sql query\n",
    "q=\"\"\"SELECT row_num from d where PM <>'None' limit 1\"\"\"    #sql query ########################Changes####################\n",
    "df1=ps.sqldf(q, locals())\n",
    "a=df1.values.flatten()\n",
    "b=(a[0])\n",
    "b\n",
    "q=\"\"\"SELECT row_num from d where PM <>'None' order by row_num desc limit 1\"\"\" \n",
    "dl2=ps.sqldf(q, locals())\n",
    "a=dl2.values.flatten()\n",
    "e=(a[0])\n",
    "e\n",
    "df=d.iloc[b:e,:] \n",
    "df.PM[df.PM == 'None'] = 0\n",
    "df.replace(0, np.NaN,inplace=True)\n",
    "df=df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1670667021564,
     "user": {
      "displayName": "Abhijeet Kumar",
      "userId": "18174877903277820406"
     },
     "user_tz": -330
    },
    "id": "17dpOG6agdPv",
    "outputId": "a550266b-dc30-4b43-d5e4-792837c786dd"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 601,
     "status": "ok",
     "timestamp": 1670667529856,
     "user": {
      "displayName": "Abhijeet Kumar",
      "userId": "18174877903277820406"
     },
     "user_tz": -330
    },
    "id": "3wDyJoJ7cIoq"
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "def DivideData(df):\n",
    "  df=df.dropna()\n",
    "  TotalLength=len(df)\n",
    "  print(\"Total Size of DataFrame \"+str(TotalLength))\n",
    "  ChunkSize=int((0.1*TotalLength))\n",
    "  print(\"Chunk Size of Dataframe \"+str(ChunkSize))\n",
    "  X_train1=df.iloc[0*ChunkSize:1*ChunkSize,0:1]\n",
    "  X_train2=df.iloc[1*ChunkSize:2*ChunkSize,0:1]\n",
    "  X_train3=df.iloc[2*ChunkSize:3*ChunkSize,0:1]\n",
    "  X_train4=df.iloc[3*ChunkSize:4*ChunkSize,0:1]\n",
    "  X_train5=df.iloc[4*ChunkSize:5*ChunkSize,0:1]\n",
    "  X_train6=df.iloc[5*ChunkSize:6*ChunkSize,0:1]\n",
    "  X_train7=df.iloc[6*ChunkSize:7*ChunkSize,0:1]\n",
    "  X_train8=df.iloc[7*ChunkSize:8*ChunkSize,0:1]\n",
    "  X_train9=df.iloc[8*ChunkSize:9*ChunkSize,0:1]\n",
    "  X_train10=df.iloc[9*ChunkSize:10*ChunkSize,0:1]\n",
    "\n",
    "  X_test1=X_train1.copy()\n",
    "  X_test2=X_train2.copy()\n",
    "  X_test3=X_train3.copy()\n",
    "  X_test4=X_train4.copy()\n",
    "  X_test5=X_train5.copy()\n",
    "  X_test6=X_train6.copy()\n",
    "  X_test7=X_train7.copy()\n",
    "  X_test8=X_train8.copy()\n",
    "  X_test9=X_train9.copy()\n",
    "  X_test10=X_train10.copy()\n",
    "\n",
    " \n",
    "  X_train1.iloc[:, 0:1] = np.nan\n",
    "  X_train2.iloc[:, 0:1] = np.nan\n",
    "  X_train3.iloc[:, 0:1] = np.nan\n",
    "  X_train4.iloc[:, 0:1] = np.nan\n",
    "  X_train5.iloc[:, 0:1] = np.nan\n",
    "  X_train6.iloc[:, 0:1] = np.nan\n",
    "  X_train7.iloc[:, 0:1] = np.nan\n",
    "  X_train8.iloc[:, 0:1] = np.nan\n",
    "  X_train9.iloc[:, 0:1] = np.nan\n",
    "  X_train10.iloc[:, 0:1] = np.nan\n",
    "\n",
    "  DF1=pd.concat([X_train1, X_test2, X_test3, X_test4, X_test5, X_test6, X_test7, X_test8, X_test9, X_test10])\n",
    "  print(DF1.shape)\n",
    "  DF2=pd.concat([X_test1, X_train2, X_test3, X_test4, X_test5, X_test6, X_test7, X_test8, X_test9, X_test10])\n",
    "  DF3=pd.concat([X_test1, X_test2, X_train3, X_test4, X_test5, X_test6, X_test7, X_test8, X_test9, X_test10])\n",
    "  DF4=pd.concat([X_test1, X_test2, X_test3, X_train4, X_test5, X_test6, X_test7, X_test8, X_test9, X_test10])\n",
    "  DF5=pd.concat([X_test1, X_test2, X_test3, X_test4, X_train5, X_test6, X_test7, X_test8, X_test9, X_test10])\n",
    "  DF6=pd.concat([X_test1, X_test2, X_test3, X_test4, X_test5, X_train6, X_test7, X_test8, X_test9, X_test10])\n",
    "  DF7=pd.concat([X_test1, X_test2, X_test3, X_test4, X_test5, X_test6, X_train7, X_test8, X_test9, X_test10])\n",
    "  DF8=pd.concat([X_test1, X_test2, X_test3, X_test4, X_test5, X_test6, X_test7, X_train8, X_test9, X_test10])\n",
    "  DF9=pd.concat([X_test1, X_test2, X_test3, X_test4, X_test5, X_test6, X_test7, X_test8, X_train9, X_test10])\n",
    "  DF10=pd.concat([X_test1, X_test2, X_test3, X_test4, X_test5, X_test6, X_test7, X_test8, X_test9, X_train10])\n",
    "\n",
    "  return DF1, DF2, DF3, DF4, DF5, DF6, DF7, DF8, DF9, DF10, X_test1, X_test2, X_test3, X_test4, X_test5, X_test6, X_test7, X_test8, X_test9, X_test10\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1670667531016,
     "user": {
      "displayName": "Abhijeet Kumar",
      "userId": "18174877903277820406"
     },
     "user_tz": -330
    },
    "id": "dVDtJ2xgcKIq"
   },
   "outputs": [],
   "source": [
    "def deployMeanModels(df):\n",
    "  df=df.dropna()\n",
    "  Feature='PM'\n",
    "  a=len(df)\n",
    "  chunkSize=int(0.1*a)\n",
    "  print(\"ChunkSize\"+str(chunkSize))\n",
    "  x=0\n",
    "  DF1, DF2, DF3, DF4, DF5, DF6, DF7, DF8, DF9, DF10, X_Test1, X_Test2, X_Test3, X_Test4, X_Test5, X_Test6, X_Test7, X_Test8, X_Test9, X_Test10= DivideData(df)\n",
    "  DF1['Mean']=DF1[Feature].fillna(DF1[Feature].mean())\n",
    "  y_true=X_Test1[Feature].values.tolist()\n",
    "  y_pred=DF1.iloc[(0*chunkSize):(1*chunkSize), -1:].values.tolist()\n",
    "  x=x+(mean_squared_error(y_true, y_pred)**0.5)\n",
    "\n",
    "  DF2['Mean']=DF2[Feature].fillna(DF2[Feature].mean())\n",
    "  y_true=X_Test2[Feature].values.tolist()\n",
    "  y_pred=DF2.iloc[(1*chunkSize):(2*chunkSize), -1:].values.tolist()\n",
    "  x=x+(mean_squared_error(y_true, y_pred)**0.5)\n",
    "\n",
    "  DF3['Mean']=DF3[Feature].fillna(DF3[Feature].mean())\n",
    "  y_true=X_Test3[Feature].values.tolist()\n",
    "  y_pred=DF3.iloc[(2*chunkSize):(3*chunkSize), -1:].values.tolist()\n",
    "  x=x+(mean_squared_error(y_true, y_pred)**0.5)\n",
    "\n",
    "  DF4['Mean']=DF4[Feature].fillna(DF4[Feature].mean())\n",
    "  y_true=X_Test4[Feature].values.tolist()\n",
    "  y_pred=DF4.iloc[(3*chunkSize):(4*chunkSize), -1:].values.tolist()\n",
    "  x=x+(mean_squared_error(y_true, y_pred)**0.5)\n",
    "\n",
    "  DF5['Mean']=DF5[Feature].fillna(DF5[Feature].mean())\n",
    "  y_true=X_Test5[Feature].values.tolist()\n",
    "  y_pred=DF5.iloc[(4*chunkSize):(5*chunkSize), -1:].values.tolist()\n",
    "  x=x+(mean_squared_error(y_true, y_pred)**0.5)\n",
    "\n",
    "  DF6['Mean']=DF6[Feature].fillna(DF6[Feature].mean())\n",
    "  y_true=X_Test6[Feature].values.tolist()\n",
    "  y_pred=DF6.iloc[(5*chunkSize):(6*chunkSize), -1:].values.tolist()\n",
    "  x=x+(mean_squared_error(y_true, y_pred)**0.5)\n",
    "\n",
    "  DF7['Mean']=DF7[Feature].fillna(DF7[Feature].mean())\n",
    "  y_true=X_Test7[Feature].values.tolist()\n",
    "  y_pred=DF7.iloc[(6*chunkSize):(7*chunkSize), -1:].values.tolist()\n",
    "  x=x+(mean_squared_error(y_true, y_pred)**0.5)\n",
    "\n",
    "  DF8['Mean']=DF8[Feature].fillna(DF8[Feature].mean())\n",
    "  y_true=X_Test8[Feature].values.tolist()\n",
    "  y_pred=DF8.iloc[(7*chunkSize):(8*chunkSize), -1:].values.tolist()\n",
    "  x=x+(mean_squared_error(y_true, y_pred)**0.5)\n",
    "\n",
    "  DF9['Mean']=DF9[Feature].fillna(DF9[Feature].mean())\n",
    "  y_true=X_Test9[Feature].values.tolist()\n",
    "  y_pred=DF9.iloc[(8*chunkSize):(9*chunkSize), -1:].values.tolist()\n",
    "  x=x+(mean_squared_error(y_true, y_pred)**0.5)\n",
    "\n",
    "  DF10['Mean']=DF10[Feature].fillna(DF10[Feature].mean())\n",
    "  y_true=X_Test10[Feature].values.tolist()\n",
    "  y_pred=DF10.iloc[(9*chunkSize):(10*chunkSize), -1:].values.tolist()\n",
    "  x=x+(mean_squared_error(y_true, y_pred)**0.5)\n",
    "\n",
    "  print(\"Average RMSE for Handling Missing Value with Mean using 10 fold cross validation is \"+str(x/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1670667531773,
     "user": {
      "displayName": "Abhijeet Kumar",
      "userId": "18174877903277820406"
     },
     "user_tz": -330
    },
    "id": "727ck9dLciDS"
   },
   "outputs": [],
   "source": [
    "def deployMedianModels(df):\n",
    "  df=df.dropna()\n",
    "  Feature='PM'\n",
    "  a=len(df)\n",
    "  chunkSize=int(0.1*a)\n",
    "  x=0\n",
    "  print(\"ChunkSize\"+str(chunkSize))\n",
    "  DF1, DF2, DF3, DF4, DF5, DF6, DF7, DF8, DF9, DF10, X_Test1, X_Test2, X_Test3, X_Test4, X_Test5, X_Test6, X_Test7, X_Test8, X_Test9, X_Test10= DivideData(df)\n",
    "  DF1['Median']=DF1[Feature].fillna(DF1[Feature].median())\n",
    "  y_true=X_Test1[Feature].values.tolist()\n",
    "  y_pred=DF1.iloc[(0*chunkSize):(1*chunkSize), -1:].values.tolist()\n",
    "  x=(mean_squared_error(y_true, y_pred)**0.5)+x\n",
    "\n",
    "  DF2['Median']=DF2[Feature].fillna(DF2[Feature].median())\n",
    "  y_true=X_Test2[Feature].values.tolist()\n",
    "  y_pred=DF2.iloc[(1*chunkSize):(2*chunkSize), -1:].values.tolist()\n",
    "  x=x+(mean_squared_error(y_true, y_pred)**0.5)\n",
    "\n",
    "  DF3['Median']=DF3[Feature].fillna(DF3[Feature].median())\n",
    "  y_true=X_Test3[Feature].values.tolist()\n",
    "  y_pred=DF3.iloc[(2*chunkSize):(3*chunkSize), -1:].values.tolist()\n",
    "  x=x+(mean_squared_error(y_true, y_pred)**0.5)\n",
    "\n",
    "  DF4['Median']=DF4[Feature].fillna(DF4[Feature].median())\n",
    "  y_true=X_Test4[Feature].values.tolist()\n",
    "  y_pred=DF4.iloc[(3*chunkSize):(4*chunkSize), -1:].values.tolist()\n",
    "  x=x+(mean_squared_error(y_true, y_pred)**0.5)\n",
    "\n",
    "  DF5['Median']=DF5[Feature].fillna(DF5[Feature].median())\n",
    "  y_true=X_Test5[Feature].values.tolist()\n",
    "  y_pred=DF5.iloc[(4*chunkSize):(5*chunkSize), -1:].values.tolist()\n",
    "  x=x+(mean_squared_error(y_true, y_pred)**0.5)\n",
    "\n",
    "  DF6['Median']=DF6[Feature].fillna(DF6[Feature].median())\n",
    "  y_true=X_Test6[Feature].values.tolist()\n",
    "  y_pred=DF6.iloc[(5*chunkSize):(6*chunkSize), -1:].values.tolist()\n",
    "  x=x+(mean_squared_error(y_true, y_pred)**0.5)\n",
    "\n",
    "  DF7['Median']=DF7[Feature].fillna(DF7[Feature].median())\n",
    "  y_true=X_Test7[Feature].values.tolist()\n",
    "  y_pred=DF7.iloc[(6*chunkSize):(7*chunkSize), -1:].values.tolist()\n",
    "  x=x+(mean_squared_error(y_true, y_pred)**0.5)\n",
    "\n",
    "  DF8['Median']=DF8[Feature].fillna(DF8[Feature].median())\n",
    "  y_true=X_Test8[Feature].values.tolist()\n",
    "  y_pred=DF8.iloc[(7*chunkSize):(8*chunkSize), -1:].values.tolist()\n",
    "  x=x+(mean_squared_error(y_true, y_pred)**0.5)\n",
    "\n",
    "  DF9['Median']=DF9[Feature].fillna(DF9[Feature].median())\n",
    "  y_true=X_Test9[Feature].values.tolist()\n",
    "  y_pred=DF9.iloc[(8*chunkSize):(9*chunkSize), -1:].values.tolist()\n",
    "  x=x+(mean_squared_error(y_true, y_pred)**0.5)\n",
    "\n",
    "  DF10['Median']=DF10[Feature].fillna(DF10[Feature].median())\n",
    "  y_true=X_Test10[Feature].values.tolist()\n",
    "  y_pred=DF10.iloc[(9*chunkSize):(10*chunkSize), -1:].values.tolist()\n",
    "  x=x+(mean_squared_error(y_true, y_pred)**0.5)\n",
    "\n",
    "  print(\"Average RMSE for Handling Missing Value with Median using 10 fold cross validation is \"+str(x/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1670667532584,
     "user": {
      "displayName": "Abhijeet Kumar",
      "userId": "18174877903277820406"
     },
     "user_tz": -330
    },
    "id": "TDayPky8eCPG"
   },
   "outputs": [],
   "source": [
    "def deployModeModels(df):\n",
    "  df=df.dropna()\n",
    "  Feature='PM'\n",
    "  a=len(df)\n",
    "  chunkSize=int(0.1*a)\n",
    "  x=0\n",
    "  print(\"ChunkSize\"+str(chunkSize))\n",
    "  DF1, DF2, DF3, DF4, DF5, DF6, DF7, DF8, DF9, DF10, X_Test1, X_Test2, X_Test3, X_Test4, X_Test5, X_Test6, X_Test7, X_Test8, X_Test9, X_Test10= DivideData(df)\n",
    "  DF1['Mode']=DF1[Feature].fillna(DF1[Feature].mode()[0])\n",
    "  y_true=X_Test1[Feature].values.tolist()\n",
    "  y_pred=DF1.iloc[(0*chunkSize):(1*chunkSize), -1:].values.tolist()\n",
    "  x=(mean_squared_error(y_true, y_pred)**0.5)+x\n",
    "\n",
    "  DF2['Mode']=DF2[Feature].fillna(DF2[Feature].mode()[0])\n",
    "  y_true=X_Test2[Feature].values.tolist()\n",
    "  y_pred=DF2.iloc[(1*chunkSize):(2*chunkSize), -1:].values.tolist()\n",
    "  x=x+(mean_squared_error(y_true, y_pred)**0.5)\n",
    "\n",
    "  DF3['Mode']=DF3[Feature].fillna(DF3[Feature].mode()[0])\n",
    "  y_true=X_Test3[Feature].values.tolist()\n",
    "  y_pred=DF3.iloc[(2*chunkSize):(3*chunkSize), -1:].values.tolist()\n",
    "  x=x+(mean_squared_error(y_true, y_pred)**0.5)\n",
    "\n",
    "  DF4['Mode']=DF4[Feature].fillna(DF4[Feature].mode()[0])\n",
    "  y_true=X_Test4[Feature].values.tolist()\n",
    "  y_pred=DF4.iloc[(3*chunkSize):(4*chunkSize), -1:].values.tolist()\n",
    "  x=x+(mean_squared_error(y_true, y_pred)**0.5)\n",
    "\n",
    "  DF5['Mode']=DF5[Feature].fillna(DF5[Feature].mode()[0])\n",
    "  y_true=X_Test5[Feature].values.tolist()\n",
    "  y_pred=DF5.iloc[(4*chunkSize):(5*chunkSize), -1:].values.tolist()\n",
    "  x=x+(mean_squared_error(y_true, y_pred)**0.5)\n",
    "\n",
    "  DF6['Mode']=DF6[Feature].fillna(DF6[Feature].mode()[0])\n",
    "  y_true=X_Test6[Feature].values.tolist()\n",
    "  y_pred=DF6.iloc[(5*chunkSize):(6*chunkSize), -1:].values.tolist()\n",
    "  x=x+(mean_squared_error(y_true, y_pred)**0.5)\n",
    "\n",
    "  DF7['Mode']=DF7[Feature].fillna(DF7[Feature].mode()[0])\n",
    "  y_true=X_Test7[Feature].values.tolist()\n",
    "  y_pred=DF7.iloc[(6*chunkSize):(7*chunkSize), -1:].values.tolist()\n",
    "  x=x+(mean_squared_error(y_true, y_pred)**0.5)\n",
    "\n",
    "  DF8['Mode']=DF8[Feature].fillna(DF8[Feature].mode()[0])\n",
    "  y_true=X_Test8[Feature].values.tolist()\n",
    "  y_pred=DF8.iloc[(7*chunkSize):(8*chunkSize), -1:].values.tolist()\n",
    "  x=x+(mean_squared_error(y_true, y_pred)**0.5)\n",
    "\n",
    "  DF9['Mode']=DF9[Feature].fillna(DF9[Feature].mode()[0])\n",
    "  y_true=X_Test9[Feature].values.tolist()\n",
    "  y_pred=DF9.iloc[(8*chunkSize):(9*chunkSize), -1:].values.tolist()\n",
    "  x=x+(mean_squared_error(y_true, y_pred)**0.5)\n",
    "\n",
    "  DF10['Mode']=DF10[Feature].fillna(DF10[Feature].mode()[0])\n",
    "  y_true=X_Test10[Feature].values.tolist()\n",
    "  y_pred=DF10.iloc[(9*chunkSize):(10*chunkSize), -1:].values.tolist()\n",
    "  x=x+(mean_squared_error(y_true, y_pred)**0.5)\n",
    "\n",
    "  print(\"Average RMSE for Handling Missing Value with Mode using 10 fold cross validation is \"+str(x/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1670667533147,
     "user": {
      "displayName": "Abhijeet Kumar",
      "userId": "18174877903277820406"
     },
     "user_tz": -330
    },
    "id": "HQrOOcwrcS7h",
    "outputId": "79a21a43-3cd1-47b1-9913-32ae43c78d74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChunkSize2824\n",
      "Total Size of DataFrame 28241\n",
      "Chunk Size of Dataframe 2824\n",
      "(28240, 1)\n",
      "Average RMSE for Handling Missing Value with Mean using 10 fold cross validation is 39.0871899948509\n",
      "ChunkSize2824\n",
      "Total Size of DataFrame 28241\n",
      "Chunk Size of Dataframe 2824\n",
      "(28240, 1)\n",
      "Average RMSE for Handling Missing Value with Median using 10 fold cross validation is 39.835272355428984\n",
      "ChunkSize2824\n",
      "Total Size of DataFrame 28241\n",
      "Chunk Size of Dataframe 2824\n",
      "(28240, 1)\n",
      "Average RMSE for Handling Missing Value with Mode using 10 fold cross validation is 60.346235808598884\n"
     ]
    }
   ],
   "source": [
    "deployMeanModels(df)\n",
    "deployMedianModels(df)\n",
    "deployModeModels(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rLMC0dNYi3Wh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOJt8jsFuCoHtV0U2K5FG1F",
   "provenance": [
    {
     "file_id": "1VmgsObwJlax3i9IFBee9YCzvJogi3Xs7",
     "timestamp": 1670667568164
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
